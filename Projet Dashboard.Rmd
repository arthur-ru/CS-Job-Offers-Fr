---
title: "French SWE Job Market"
output:
  flexdashboard::flex_dashboard:
    theme:
      bootswatch: flatly
    orientation: columns
    vertical_layout: fill
    source_code: embed
    
runtime: shiny
resource_files:
- data/finalData.csv
- scrapOfferInfo.py
- scrapHardSkills.py
- scrapOffersLink.py
- preprocessing.ipynb
- Collecte_rapport_g2.pdf
- departements/departements.geojson

---


```{r setup, include=FALSE}
library(flexdashboard)
library(leaflet)
library(ggplot2)
library(maps)
library(readr)
library(dplyr)
library(ggmap)
library(tmaptools)
library(sf)
library(tidyr)
library(shiny)
library(plotly)
library(rmapshaper)
library(stringr)
library(corrplot)
library(randomForest)
library(formattable)
library(caret)

finalData <- read.csv("data/finalData.csv", dec=".", sep = ",")
dep_offers <- finalData$department
dep_offers_count <- table(dep_offers)
dep_offers_count <- as.data.frame(dep_offers_count)
names(dep_offers_count) <- c("num_dep", "nb_offers") 


france_departments <- st_read("departements/departements.geojson")
france_departments$code_insee <- gsub("M", "", france_departments$code)
france_departments$code_insee <- gsub("D", "", france_departments$code)
france_departments$code_insee <- as.numeric(france_departments$code)
france_departments <- subset(france_departments, code <= 95)

france_departments <- merge(france_departments, dep_offers_count, by.x="code", by.y="num_dep", all.x=TRUE)

# Fill NA values in nb_offers column with zeros
france_departments$nb_offers <- ifelse(is.na(france_departments$nb_offers), 0, france_departments$nb_offers)


```

# Presentation {data-icon="fa-home"}
## Column 1 {data-width=650}
### **Presentation of the subject**
The **French Software Engineering Job Market** is a project that aims to **analyze and visualize the job offers** in the software engineering field in France. By analyzing a dataset of job offers, we provide insights into the demand for software engineers in **different counties and sectors**, as well as the required skills and salary distribution.

In fact, individuals starting in the tech domain need to understand which programming languages and technologies they need to master in order to find employment opportunities.

Our project utilizes various R packages such as `flexdashboard`, `leaflet`, `ggplot2`, and `shiny` to create interactive dashboards and visualizations. The dashboards allow users to **explore the data, filter by county and sector**, and gain a better understanding of the job market trends.

In addition to the visualizations, we also perform data preprocessing and analysis. We merge the job offer data with geographical information to map the offers by county. We also analyze the skills required by different sectors and examine the correlation between telecommuting, number of skills, and salary.

The dataset of 1000+ job offers was sourced through **web scraping** from Hello Work, a job listing site where web scraping is legally permitted, providing a rich source of information for our analysis.

Overall, our project provides **valuable insights into the French software engineering job market**. It helps job seekers understand the demand for their skills in different counties and sectors, and it provides employers with information on the current job market trends.

## Column 2 {data-width=350}

###
![](https://i.ibb.co/MNZ1nhD/mines-ales.png){}



### Dashboards made by :

<ul>
  <li>EL-OTHMANI Youssef</li>
  <li>FLANDRE Noe</li>
  <li>MICHELIN Marc-Alexandre</li>
  <li>RUBIO Arthur</li>
  <li>TERRASSON Ludovic</li>
</ul>


# Database {data-icon="fa-database"}
Column {.tabset}
-----------------------------------------------------------------------
### Data

```{r}
DT::datatable(finalData, 
    options = list( pageLength = 25, 
    dom = 'Bfrtip', 
    buttons = c('csv')),
    extensions = 'Buttons',
    height = 1000,
    width = 1000,
    colnames = c("Job Title", "Company", "Contract Type", "Education Level", "Sector", "Remote", "Years of Exp", "Salary (€)", "Skills", "City","County n°")
)

```

### Description of the data


#### `finalData.csv` Dataset Description
The `finalData.csv` dataset was sourced through web scraping from Hello Work, a job listing site where web scraping is legally permitted. It comprises various attributes related to job postings gathered for analysis and machine learning applications. Below is the types of information it includes:

- **Job Title (`job_title`)**: Title of the job posting, which could include positions like "Software Engineer".
- **Company Name (`company_name`)**: Name of the company offering the job position.
- **Contract Type (`contract_type`)**: Type of employment contract being offered, such as CDI (Permanent Contract), CDD (Fixed-Term Contract), Internship, etc.
- **Education Level (`niveau_etude`)**: Minimum level of education required for the job, specified as diploma levels (e.g., "Bac +5" equivalent to a Master's degree in the French education system).
- **Sector (`secteur`)**: Industry or sector the job belongs to, for example, Healthcare, Tech.
- **Remote Work (`teletravail`)**: Boolean indicating whether the job offers the possibility for remote work.
- **Experience Required (`experience`)**: Professional experience required for the job, possibly indicated in years.
- **Salary (`salaire`)**: Annual salary offered for the position expressed in euros.
- **Skills (`skills`)**: Array of specific skills mentioned in the job listing (programming languages, software proficiency, or other professional competencies).
- **City (`city`)**: City where the job is located.
- **Department (`department`)**: Administrative division where the job is located.


### Data Preprocessing

We conducted a thorough preprocessing phase to **enhance the quality and usability of the dataset**. This involved several key steps aimed at standardizing and refining the data for subsequent analysis.
Initially, we converted the `experience` column to string format to facilitate handling of any missing values. Next, we extracted numerical experience values from this column to **quantify the level of expertise required** for each job offer.
Additionally, we processed the `salaire` column to extract average salary information, rounded it for precision, and replaced any missing values with the computed average.
Geographical analysis was also improved by **splitting the `location` column into `city` and `department`** components, allowing for more granular insights into job distribution across regions. Furthermore, we transformed the `skills` column into a **list format**, removing duplicates and converting all entries to lowercase for consistency. These preprocessing steps collectively ensured that the dataset was cleansed, standardized, and ready for further analysis.

```{r}
# Example preprocessed experience data
example_data <- data.frame(
  original_experience = c("Exp. 5 ans", "Exp. 1 à 7 ans", NA, "Exp. + 7 ans"),
  original_salary = c("40 000 - 45 000 EUR par an", "819 - 2 100 EUR par mois", NA, "35 000 - 38 000 EUR par an"),
  original_location = c("Paris 1er - 75", "Paris - 75", "Lyon 1er - 69", "Lyon - 69"),
  'dep' = c('','','','')
)


# Example preprocessed experience data
example_data_processed <- data.frame(
  processed_experience = c(5, 1, NA, 7),  # Processed values (example)
  processed_salary = c(42500, 17514, 32171, 36500),  # Processed values (example)
  processed_city = c("Paris", "Paris", "Lyon", "Lyon"),
  procced_dep = c(75, 75, 69, 69)
)


# Use formattable within a div with width and centering
HTML(sprintf('<div style="display: flex; align-items: center; justify-content: center;">
  <div style="width: 40%%; margin-right: 10px;">%s</div>
    <div style="width: 10%%; margin-right: 10px;">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 25 25"><path style="fill:#232326" d="m17.5 5.999-.707.707 5.293 5.293H1v1h21.086l-5.294 5.295.707.707L24 12.499l-6.5-6.5z" data-name="Right"/></svg>
        </div>
        
        <div style="width: 40%%; margin-left: 10px;">%s</div>
          </div>',
             formattable(
               example_data
             ),
             formattable(
               example_data_processed
             )
))

ui <- fluidPage( downloadButton("downloadScriptPreprocessing", "Download Script"))

server <- function(input, output) {
  output$downloadScriptPreprocessing <- downloadHandler(
    filename = function() {
      "preprocessing.ipynb"  
    },
    content = function(file) {
      file.copy("preprocessing.ipynb", file)
    }
  )
}

shinyApp(ui, server)


```

### Scraping Process
```{r}
h4("Scraping Process Overview:")

ui <- fluidPage(
  p(HTML("<strong>Initial Data Collection:</strong> We begin by scraping all the job offer links from 'Hello work'within the software engineering domain. These links are then stored in a structured format, typically a JSON file, for further processing.")),
  
  downloadButton("downloadScriptScrapLinks", "Download Script"),
  p(""),
  p(HTML("<strong>Detailed Offer Extraction:</strong> After acquiring the offer links, we proceed to scrape the detailed information from each individual job listing. This includes key details such as job title, company name, contract type, required skills, salary range, and location.")),
  
     downloadButton("downloadScriptScrapInfo", "Download Script"),
  p(""),
  p(HTML("<strong>Skill Extraction Methodology:</strong> One challenge we encounter is that skills are often mentioned within paragraphs of text rather than in structured fields. To address this, we employ a custom methodology. We utilize a predefined dictionary of skills and systematically search for their occurrence within the textual descriptions of job offers. This allows us to accurately identify and extract the required skills.")),
  
  p(HTML("<strong>Comprehensive Skill Scraping:</strong> Additionally, we conduct a thorough scraping process to gather a comprehensive list of relevant skills. This ensures that our skill dictionary is up-to-date and covers a wide range of industry-specific and in-demand skills.")),
 downloadButton("downloadScrapHardSkills", "Download Script")


)


server <- function(input, output) {
  output$downloadScriptScrapLinks <- downloadHandler(
    filename = function() {
      "scrapOffersLink.py"  
    },
    content = function(file) {
      file.copy("scrapOffersLink.py", file)
    }
  )
  output$downloadScriptScrapInfo <- downloadHandler(
    filename = function() {
      "scrapOfferInfo.py"  
    },
    content = function(file) {
      file.copy("scrapOfferInfo.py", file)
    }
  )
  
  output$downloadScrapHardSkills <- downloadHandler(
    filename = function() {
      "scrapHardSkills.py"  
    },
    content = function(file) {
      file.copy("scrapHardSkills.py", file)
    }
  )
  
}

shinyApp(ui, server)

```

# 🗺️ Offers by counties {data-navmenu="📈 Visualization"}
## Column 1 {data-width=750}
### Offers by counties
```{r}

france_departments_simplified <- ms_simplify(france_departments, keep = 0.1)
# Define UI
ui <- fluidPage(
  # Call the UI output to render the map
  uiOutput("mapUI")
)

# Define server logic
server <- function(input, output) {
  
  output$map <- renderLeaflet({
    leaflet(data = france_departments_simplified) %>%
      addProviderTiles(providers$CartoDB.Positron) %>%
      setView(lng = 2.2137, lat = 46.2276, zoom = 6) %>%
      addPolygons(
        fillColor = ~colorNumeric("YlOrRd", domain = france_departments_simplified$nb_offers)(nb_offers),
        color = "#BDBDC3",
        weight = 1,
        fillOpacity = 1,
        opacity = 1,
        smoothFactor = 0.7,
        popup = ~paste("Nombre d'offres dans ", nom, ": ", nb_offers)
      )
  })
  
  output$mapUI <- renderUI({
    leafletOutput("map", height = "500px")
  })
}

# Run the application
shinyApp(ui = ui, server = server)



```

## Column 2  {data-width=250}
### Top counties

```{r}
top_regions <- france_departments
top_regions <- st_drop_geometry(top_regions)
top_regions <- top_regions[, c("nom", "nb_offers")]
top_regions <- top_regions[order(-top_regions$nb_offers), ][1:15, ]
top_regions$nb_offers <- as.integer(top_regions$nb_offers)
ui = fluidPage(
    # Table output
    fluidRow(
      column(width = 12, tableOutput("regionsTable"))
    )
)
server = function(input, output) {
    # Render the table
    output$regionsTable <- renderTable({
      colnames(top_regions) <- c("Name", "Nb of offers")
      return(top_regions)
    })
}

shinyApp(ui = ui, server = server)
```



# ⚙️ Skills required {data-navmenu="📈 Visualization" }
```{r}

output$table <- renderTable({
    if (input$secteur == "All Sectors") {
      sector_data <- finalData %>%
        mutate(skills = gsub("\\[|\\]|'", "", skills),
               skills = strsplit(skills, ",\\s*")) %>%
        unnest(skills)
    } else {
      sector_data <- finalData %>%
        filter(secteur == input$secteur) %>%
        mutate(skills = gsub("\\[|\\]|'", "", skills),
               skills = strsplit(skills, ",\\s*")) %>%
        unnest(skills)
    }
    
    skills_info <- sector_data %>%
      count(skills, name = "Number of occurences") %>%
      arrange(desc(`Number of occurences`)) %>%
      mutate(skills = ifelse(row_number() <= 15, skills, NA)) %>%
      na.omit()
    
    skills_info
  })
  
output$pieChart <- renderPlotly({
    if (input$secteur == "All Sectors") {
      sector_data <- finalData %>%
        mutate(skills = gsub("\\[|\\]|'", "", skills),
               skills = strsplit(skills, ",\\s*")) %>%
        unnest(skills)
    } else {
      sector_data <- finalData %>%
        filter(secteur == input$secteur) %>%
        mutate(skills = gsub("\\[|\\]|'", "", skills),
               skills = strsplit(skills, ",\\s*")) %>%
        unnest(skills)
    }
    
    skills_info <- sector_data %>%
      count(skills, name = "Number of occurences") %>%
      arrange(desc(`Number of occurences`)) %>%
      mutate(skills = ifelse(row_number() <= 15, skills, NA)) %>%
      na.omit()
    
    plot_ly(skills_info, labels = ~skills, values = ~`Number of occurences`, type = 'pie') %>%
      layout(title = "The 15 most demanded skills by sector", margin = list(t = 50))  # Add margin to move the pie chart down
  })
  
output$resultText <- renderUI({  # Use renderUI instead of renderText
    HTML("The pie chart displays the most demanded 15 skills. The most in-demand programming languages include <strong>Python</strong>, <strong>Java</strong>, and <strong>PHP</strong>, with PHP maintaining high demand despite being launched in 1994.<br>
    Furthermore, deployment-related skills such as <strong>Docker</strong>, <strong>Kubernetes</strong>, and <strong>AWS</strong> are prominent in the most demanded skills. <br>
    The most popular framework is <strong>Angular</strong>, known for its versatility to build dynamic web apps. <br>
    Proficiency in <strong>Linux</strong> is also essential, as familiarity with various operating systems is advantageous. <br>
    Additionally, <strong>DevOps</strong>, a collaborative approach emphasizing communication and integration between software development and IT operations teams, is a significant skill sought after in the industry. <br>
    Through this pie chart, we have learned that not only languages are in demand, but also <strong>deployment and framework-related</strong> skills. This is coherent with the need of companies to have a versatile team.")
  })




```

## column 1 {data-width=300}
###

```{r}
selectInput("secteur", label = "Secteur",
                       choices = c("All Sectors", unique(finalData$secteur)), multiple = FALSE, selected = NULL)
tableOutput("table")

```


## column 2

###

```{r}
 plotlyOutput("pieChart")
```

### Observations

```{r}
uiOutput("resultText")
br()
```

# 💰 Salaries by region (€) {data-navmenu="📈 Visualization" }
```{r}
Hauts_de_France <- c(2, 59, 60, 62, 80)
Ile_de_France <- c(75, 77, 78, 91, 92, 93, 94, 95)
Grand_Est <- c(8, 10, 51, 52, 54, 55, 57, 67, 68, 88)
Normandie <- c(14, 27, 50, 61, 76)
Bretagne <- c(22, 29, 35, 56)
Pays_de_la_Loire <- c(44, 49, 53, 72, 85)
Centre_Val_de_Loire <- c(18, 28, 36, 37, 41, 45)
Bourgogne_Franche_Comte <- c(21, 25, 39, 58, 70, 71, 89, 90)
Nouvelle_Aquitaine <- c(16, 17, 19, 23, 24, 33, 40, 47, 64, 79, 86, 87)
Occitanie <- c(9, 11, 12, 30, 31, 32, 34, 46, 48, 65, 66, 81, 82)
Auvergne_Rhone_Alpes <- c(1, 3, 7, 15, 26, 38, 42, 43, 63, 69, 73, 74)
Provence_Alpes_Cote_d_Azur <- c(4, 5, 6, 13, 83, 84)

regions <- list(
  "Hauts de France" = Hauts_de_France,
  "Ile de France" = Ile_de_France,
  "Grand Est" = Grand_Est,
  "Normandie" = Normandie,
  "Bretagne" = Bretagne,
  "Pays de la Loire" = Pays_de_la_Loire,
  "Centre Val de Loire" = Centre_Val_de_Loire,
  "Bourgogne Franche Comte" = Bourgogne_Franche_Comte,
  "Nouvelle Aquitaine" = Nouvelle_Aquitaine,
  "Occitanie" = Occitanie,
  "Auvergne Rhone Alpes" = Auvergne_Rhone_Alpes,
  "Provence Alpes Cote d'Azur" = Provence_Alpes_Cote_d_Azur
)

regions_df <- data.frame(
  region = rep(names(regions), lengths(regions)),
  department = unlist(regions)
)
output$regionPlot <- renderPlotly({
  # Check if "All regions" is selected or a specific region
  if (input$region == "All regions") {
    location_data <- finalData
  } else {
    # Get department codes for the selected region
    selected_departments <- regions[[input$region]]
    
    # Filter the data for those departments
    location_data <- finalData %>% 
      filter(department %in% selected_departments)
  }
  
  # Calculate the mean salary
  mean_salary <- mean(location_data$salaire)
  
  # Plot the histogram of salaries
  p <- ggplot(location_data, aes(x = salaire)) +
    geom_histogram(fill = "lightblue", color = "black", bins = 20) +
    labs(title = "Distribution of salaries by region",
         x = "Salaries", y = "") +
    theme_minimal() +
    geom_vline(xintercept = mean_salary, color = "#200be0", linetype = "dashed")  # Add a dashed red line for the mean salary
  # Calculate quartiles, top 10% of best salaries, top 10% of worst salaries, maximum and minimum values
  quartiles <- quantile(location_data$salaire, probs = c(0.1, 0.5, 0.9))
  top_10_best <- quantile(location_data$salaire, probs = 0.9)
  top_10_worst <- quantile(location_data$salaire, probs = 0.1)
  
  # Add vertical lines for the top 10% of best and worst salaries
  p <- p +
    geom_vline(xintercept = top_10_best, color = "#00ff00", linetype = "dashed") +
    geom_vline(xintercept = top_10_worst, color = "#ff0000", linetype = "dashed")
  
  ggplotly(p)
})

output$regionTable <- renderTable({
  # Check if "All regions" is selected or a specific region
  if (input$region == "All regions") {
    location_data <- finalData
  } else {
    # Get department codes for the selected region
    selected_departments <- regions[[input$region]]
    
    # Filter the data for those departments
    location_data <- finalData %>% 
      filter(department %in% selected_departments)
  }
  
  # Calculate quartiles, top 10% of best salaries, top 10% of worst salaries, maximum and minimum values
  quartiles <- quantile(location_data$salaire, probs = c(0.1, 0.5, 0.9))
  top_10_best <- quantile(location_data$salaire, probs = 0.9)
  top_10_worst <- quantile(location_data$salaire, probs = 0.1)
  max_value <- max(location_data$salaire)
  min_value <- min(location_data$salaire)
  
  # Create the table
  data.frame(
      "Salaries" = c("10% Best", "Median", "Mean", "10% Worst", "Maximum", "Minimum"),
      "Value" = format(c(top_10_best, quartiles[2], mean(location_data$salaire), top_10_worst, max_value, min_value), nsmall = 0)
    )
})

output$regionBoxPlot <- renderPlotly({
  # Check if "All regions" is selected or a specific region
  if (input$region == "All regions") {
    location_data <- finalData
  } else {
    # Get department codes for the selected region
    selected_departments <- regions[[input$region]]
    
    # Filter the data for those departments
    location_data <- finalData %>% 
      filter(department %in% selected_departments)
  }
  
  plot_ly(location_data, y = ~salaire, type = "box") %>%
  layout(title = "Boxplot of Salary")
  
})

```

## column 1
### Graph plot
```{r}
selectInput("region", label = "Region",
            choices = c("All regions", names(regions)),
            multiple = FALSE,
            selected = "All regions") 
column(
  width = 12,


plotlyOutput("regionPlot", height = "400px")
)

```

## column 2 {data-width=400}
### Statistics table
```{r}
tableOutput("regionTable")  # Adjust height as needed
```

### Boxplot of Salary by Region
```{r}
plotlyOutput("regionBoxPlot", height = "400px")

```


# 📊 Salaries by sectors {data-navmenu="📈 Visualization" }

```{r}

output$secteurPlot <- renderPlotly({
  if (input$secteur == "All sectors") {
    secteur_data <- finalData
  } else {
    secteur_data <- finalData %>% filter(secteur == input$secteur)
  }
  
  mean_salary <- mean(secteur_data$salaire)
  top_10_best <- quantile(secteur_data$salaire, probs = 0.9)
  top_10_worst <- quantile(secteur_data$salaire, probs = 0.1)
  
  # Tracer l'histogramme
  ggplot(secteur_data, aes(x = salaire)) +
    geom_histogram(fill = "lightblue", color = "black", bins = 20) +
    geom_vline(xintercept = mean_salary, color = "#200be0", linetype = "dashed") +
    geom_vline(xintercept = top_10_best, color = "#00ff00", linetype = "dashed") +
    geom_vline(xintercept = top_10_worst, color = "#ff0000", linetype = "dashed") +
    labs(title = "Distribution of salaries by sector",
         x = "salaire", y = "") +
    theme_minimal() 
  
})

output$sectorBoxPlot <- renderPlotly({
  # Check if "All regions" is selected or a specific region
  if (input$secteur == "All sectors") {
    secteur_data <- finalData
  } else {
    secteur_data <- finalData %>% filter(secteur == input$secteur)
  }
  
  plot_ly(secteur_data, y = ~salaire, type = "box") %>%
  layout(title = "Boxplot of Salary")
  
})


output$sectorTable <- renderTable({
  # Check if "All regions" is selected or a specific region
   if (input$secteur == "All sectors") {
    secteur_data <- finalData
  } else {
    secteur_data <- finalData %>% filter(secteur == input$secteur)
  }
  
  # Calculate quartiles, top 10% of best salaries, top 10% of worst salaries, maximum and minimum values
  quartiles <- quantile(secteur_data$salaire, probs = c(0.1, 0.5, 0.9))
  top_10_best <- quantile(secteur_data$salaire, probs = 0.9)
  top_10_worst <- quantile(secteur_data$salaire, probs = 0.1)
  max_value <- max(secteur_data$salaire)
  min_value <- min(secteur_data$salaire)
  
  # Create the table
  data.frame(
      "Salaries" = c("10% Best", "Median", "Mean", "10% Worst", "Maximum", "Minimum"),
      "Value" = format(c(top_10_best, quartiles[2], mean(secteur_data$salaire), top_10_worst, max_value, min_value), nsmall = 0)
    )
})

```


## column 1
### Graph plot
```{r}
selectInput("secteur", label = "Secteur",
choices = c("All sectors", unique(finalData$secteur)), multiple = FALSE, selected = NULL)

column(
  width = 12,
plotlyOutput("secteurPlot", height = "400px")
)
```

## column 2 {data-width=400}
### Statistics table
```{r}
tableOutput("sectorTable") 
```


### Boxplot of Salary by Sector
```{r}
plotlyOutput("sectorBoxPlot", height = "400px")
```

# 🔢 Basic Analysis {data-navmenu="📐 Modelization"}
## Column1 {data-width="650"}
### Mean Salary
```{r}
renderValueBox({
valueBox("43 826€", icon = "fa-euro-sign", color = "#4fdfff")
})
```

### Sector with most offers
```{r}
renderValueBox({
valueBox("Tech", icon = "fa-laptop", color = "#1592ff")
})
```

### Most asked skills
```{r}
renderValueBox({
valueBox("Python, Java, PHP, Git", icon = "fa-brain", color = "#6810ff")
})
```

### Percentage of remote jobs
```{r}
renderValueBox({
valueBox("42%", icon = "fa-house", color = "#8400ff")
})
```

## Column2 {data-width="350"}
### Observations
The dataset is somewhat **right-skewed** since the mean (average) is slightly higher than the median.

Most of the data points (75%) lie within the range of approximately 13 464€ to 43 653€.

- The maximum value of 90 000€ suggests that there are some outliers in the dataset, which are significantly higher than the rest of the values. These outliers could represent unusually high salaries.

# 🔍 Correlation matrix {data-navmenu="📐 Modelization" }
## Column 1 {data-width=650}
### Correlation matrix
```{r}
arrondir_dizaine_millier <- function(salaire) {
  salaire_arrondi <- round(salaire / 10000) * 10000
  return(salaire_arrondi)
}

finalDataCopy <- finalData

# Apply the function to the salary column
finalDataCopy$salaire2 <- arrondir_dizaine_millier(finalDataCopy$salaire)
finalDataCopy <- finalDataCopy %>%
  mutate(teletravail = ifelse(teletravail == "False", -1, 1))
finalDataCopy$number_of_skills <- str_count(finalDataCopy$skills, "\\w+")
data_selected <- finalDataCopy[, c("teletravail", "department", "number_of_skills", "salaire2")]
data_selected <- na.omit(data_selected)
corr_matrix <- cor(data_selected)
rownames(corr_matrix) <- c("Remote", "County", "Nb of Skills", "Salary")
colnames(corr_matrix) <- c("Remote", "County", "Nb of Skills", "Salary")
corrplot(corr_matrix, method="ellipse")

data_selected$salaire2 <- as.factor(data_selected$salaire2)
# Séparation des données en ensembles d'entraînement et de test
set.seed(123) # Pour la reproductibilité
ind <- sample(2, nrow(data_selected), replace = TRUE, prob = c(0.8, 0.2))
train <- data_selected[ind==1,]
test <- data_selected[ind==2,]
model <- randomForest(salaire2~., data=train, proximity=TRUE)
predictions <- predict(model, newdata=test)
confusion_matrix <- confusionMatrix(predictions, test$salaire2)
accuracy <- confusion_matrix$overall['Accuracy']
```

### Random Forest model accuracy
```{r}
gauge(value = as.integer(round(accuracy,2)*100), min = 0, max = 100)
```
## Column 2 {data-width=650}
### Matrix Observations:

This heatmap displays the correlation coefficients between **Remote**, **County**, **Nb of Skills**, and **Salary**, with each cell's color denoting the correlation's strength and direction: blue for positive, red for negative, and grey for none, although only positive correlations are evident here. 

- The **strongest positive correlations are between Remote and County, and also Nb of Skills**, hinting that **remote jobs may require more skills**. 

- Salary exhibits a **moderate positive correlation** with Remote and County, implying a connection between higher salaries and remote work options or regional job markets, particularly notable in areas like Paris where salaries tend to be higher. Conversely, the **negative correlation between Salary and Number of Skills** suggests that higher salaries are associated with roles demanding expertise in a narrower range of skills, contrasting with entry-level positions that require a broader skill set without requiring expertise in each.
The moderate correlations between salary and the other factors can be explained by the importance of salary negotiations in the tech industry.


# Conclusion {data-icon="fa-pen-to-square"}
## Column 1 {data-width=500}
### Limitations

It is important to note that this study has its limits. 

- First, the dataset was sourced through web scraping from Hello Work, a job listing site where web scraping is legally permitted. However, the dataset may not be fully representative of the entire job market, as it only includes **job postings from this specific site**. Also, the dataset may not be fully up-to-date, as it was collected at a specific point in time.

- It is important to note that the data, particularly regarding salary information, may not be entirely precise, given that it's often approximated and subject to negotiation, influenced by factors such as years of experience and previous employment history.

- Secondly, another limitation of our project is the prevalence of the **hidden job market**, as many job openings are not posted online and remain inaccessible through web scraping.

- Finally, the tech job market is known for its **dynamic nature** with constant advancements and evolving technologies. As a result, the skills that are highly sought after in the industry can change rapidly. What may be in high demand today could become less relevant tomorrow as new technologies emerge and market needs shift. 

## Column 2 {data-width=500}
### Conclusion

In conclusion, our project provides valuable insights into the French software engineering job market. Here are some of our major findings:

- **Regional Hegemony**: The Paris region holds a commanding lead nationally, with both higher salaries and a greater number of job opportunities.

- **Skill Demand**: The market demands a mix of classic programming skills, such as Python and Java, as well as unexpected ones like PHP, highlighting the value of developer versatility along with proficiency in cloud tools like AWS and Docker.

- **Salary and Skills Correlation**: A negative correlation exists between salary and specific skills, indicating specialized language experts are in demand for senior roles, unlike generalists.

- **Tech Sector Salaries**: Salaries in the tech sector surpass those in other fields, confirming its status as a lucrative employment market.

```{r}
ui <- fluidPage(
downloadButton("downloadSRapport", "Download Report ")
)


server <- function(input, output) {
  output$downloadSRapport <- downloadHandler(
    filename = function() {
      "Collecte_rapport_g2.pdf"  
    },
    content = function(file) {
      file.copy("Collecte_rapport_g2.pdf", file)
    }
  )
}
shinyApp(ui, server)

```